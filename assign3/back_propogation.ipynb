{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPlIxCfGI1nVpsosvkB6Uzv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":9,"metadata":{"id":"hl3D9DWx3jZn","executionInfo":{"status":"ok","timestamp":1730234942572,"user_tz":240,"elapsed":156,"user":{"displayName":"Leihan Chen","userId":"05314281339797872064"}}},"outputs":[],"source":["import numpy as np\n","\n","# Define the sigmoid activation function\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","# Define the derivative of the components in ANN with sigmoid activation\n","def sigmoid_derivative(x):\n","    return x * (1 - x)\n","\n","def square_error_derivative(o1, O1):\n","    return (o1 - O1)\n","\n","def linear_derivative(w):\n","    return w\n","\n","def last_layer_derivative(o1, O1, h1):\n","    return square_error_derivative(o1, O1) * sigmoid_derivative(o1) * linear_derivative(h1)\n","\n","def bias_last_layer_derivative(o1, O1):\n","    return square_error_derivative(o1, O1) * sigmoid_derivative(o1)\n","\n","def first_layer_derivative(o1, O1, o2, O2, w1, w2, h1, i1):\n","    last_layer = square_error_derivative(o1, O1) * sigmoid_derivative(o1) * w1  + square_error_derivative(o2, O2) * sigmoid_derivative(o2) * w2\n","    return last_layer * sigmoid_derivative(h1) * linear_derivative(h1) * i1\n","\n","\n","# Calculate forward propogation with the sigmoid activation function\n","def forward_prop(i1, i2, w1, w2, w3, w4, b1, b2):\n","    z1 = i1 * w1 + i2 * w3 + b1\n","    a1 = sigmoid(z1)\n","    z2 = i1 * w2 + i2 * w4 + b2\n","    a2 = sigmoid(z2)\n","    return a1, a2\n","\n","def square_error(o1, o2, O1, O2):\n","    return 0.5 * ((o1 - O1)**2 + (o2 - O2)**2)\n","\n","def update_weight(w, a, dw):\n","    return w - a * dw\n","\n","# Initinal variable in the two-layer ANN network\n","w1 = 0.8\n","w2= -0.2\n","w3 = -0.4\n","w4 = 0.3\n","b11 = 0.1\n","b12 = 0.6\n","i1 = 0.9\n","i2 = 0.3\n","w5 = -0.7\n","w6 = 0.5\n","w7 = -0.3\n","w8 = 0.6\n","b21 = 0.2\n","b22 = 0.4\n","O1= 0.01\n","O2= 0.99\n","a = 0.5"]},{"cell_type":"code","source":["# Question1 forward propogation\n","h1, h2 = forward_prop(i1, i2, w1, w2, w3, w4, b11, b12)\n","print(h1, h2)\n","o1, o2 = forward_prop(h1, h2, w5, w6, w7, w8, b21, b22)\n","print(o1, o2)\n","error = square_error(o1, o2, O1, O2)\n","print(error)\n","\n","# Question2 backward propogation\n","# Get the gradient of all last layer\n","print(last_layer_derivative(o1, O1, h1))\n","print(last_layer_derivative(o2, O2, h1))\n","print(last_layer_derivative(o1, O1, h2))\n","print(last_layer_derivative(o2, O2, h2))\n","print(bias_last_layer_derivative(o1, O1))\n","print(bias_last_layer_derivative(o2, O2))\n","# Get the weight of all first layer\n","print(first_layer_derivative(o1, O1, o2, O2, w5, w6, h1, i1))\n","print(first_layer_derivative(o1, O1, o2, O2, w7, w8, h2, i1))\n","print(first_layer_derivative(o1, O1, o2, O2, w5, w6, h1, i2))\n","print(first_layer_derivative(o1, O1, o2, O2, w7, w8, h1, i2))\n","print(first_layer_derivative(o1, O1, o2, O2, w5, w6, h1, 1))\n","print(first_layer_derivative(o1, O1, o2, O2, w7, w8, h2, 1))\n","\n","# Update all weights\n","print(\"weight updating below\")\n","print(update_weight(w1, a, first_layer_derivative(o1, O1, o2, O2, w5, w6, h1, i1)))\n","print(update_weight(w2, a, first_layer_derivative(o1, O1, o2, O2, w7, w8, h2, i1)))\n","print(update_weight(w3, a, first_layer_derivative(o1, O1, o2, O2, w5, w6, h1, i2)))\n","print(update_weight(w4, a, first_layer_derivative(o1, O1, o2, O2, w7, w8, h2, i2)))\n","print(update_weight(w5, a, last_layer_derivative(o1, O1, h1)))\n","print(update_weight(w6, a, last_layer_derivative(o2, O2, h1)))\n","print(update_weight(w7, a, last_layer_derivative(o1, O1, h2)))\n","print(update_weight(w8, a, last_layer_derivative(o2, O2, h2)))\n","print(update_weight(b21, a, bias_last_layer_derivative(o1, O1)))\n","print(update_weight(b22, a, bias_last_layer_derivative(o2, O2)))\n","print(update_weight(b11, a, first_layer_derivative(o1, O1, o2, O2, w5, w6, h1, 1)))\n","print(update_weight(b12, a, first_layer_derivative(o1, O1, o2, O2, w7, w8, h2, 1)))\n","\n","# Question3 Update the weight\n","w1 = update_weight(w1, a, first_layer_derivative(o1, O1, o2, O2, w5, w6, h1, i1))\n","w2 = update_weight(w2, a, first_layer_derivative(o1, O1, o2, O2, w7, w8, h2, i1))\n","w3 = update_weight(w3, a, first_layer_derivative(o1, O1, o2, O2, w5, w6, h1, i2))\n","w4 = update_weight(w4, a, first_layer_derivative(o1, O1, o2, O2, w7, w8, h2, i2))\n","w5 = update_weight(w5, a, last_layer_derivative(o1, O1, h1))\n","w6 = update_weight(w6, a, last_layer_derivative(o2, O2, h1))\n","w7 = update_weight(w7, a, last_layer_derivative(o1, O1, h2))\n","w8 = update_weight(w8, a, last_layer_derivative(o2, O2, h2))\n","b21 = update_weight(b21, a, bias_last_layer_derivative(o1, O1))\n","b22 = update_weight(b22, a, bias_last_layer_derivative(o2, O2))\n","b11 = update_weight(b11, a, first_layer_derivative(o1, O1, o2, O2, w5, w6, h1, 1))\n","b12 = update_weight(b12, a, first_layer_derivative(o1, O1, o2, O2, w7, w8, h2, 1))\n","h1, h2 = forward_prop(i1, i2, w1, w2, w3, w4, b11, b12)\n","print(\"New error after weight updating\")\n","print(h1, h2)\n","o1, o2 = forward_prop(h1, h2, w5, w6, w7, w8, b21, b22)\n","print(o1, o2)\n","error = square_error(o1, o2, O1, O2)\n","print(error)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c6QFUo-1l250","executionInfo":{"status":"ok","timestamp":1730234950342,"user_tz":240,"elapsed":135,"user":{"displayName":"Leihan Chen","userId":"05314281339797872064"}},"outputId":"db659076-db9d-4209-8ee5-d20d4a021ef7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6681877721681662 0.6248064744684293\n","0.3881314542973173 0.7519384871981952\n","0.09982834030324401\n","0.06000373665233793\n","-0.029670810857796024\n","0.05610806529881223\n","-0.027744468694068596\n","0.08980071044645889\n","-0.04440489948135211\n","-0.011341548870451365\n","-0.007063454486481706\n","-0.003780516290150455\n","-0.0023814362086154598\n","-0.012601720967168184\n","-0.00784828276275745\n","weight updating below\n","0.8056707744352257\n","-0.19646827275675915\n","-0.3981097418549248\n","0.3011772424144136\n","-0.7300018683261689\n","0.514835405428898\n","-0.3280540326494061\n","0.6138722343470343\n","0.15509964477677057\n","0.42220244974067606\n","0.1063008604835841\n","0.6039241413813787\n","New error after weight updating\n","0.6708915125129001 0.6266063947469758\n","0.3681379954680606 0.7599230025623214\n","0.09059912427390907\n"]}]}]}